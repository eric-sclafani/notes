{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the network\n",
    "\n",
    "\n",
    "In pytorch, **all networks** must subclass from the `Module` class.\n",
    "\n",
    "Underneath the hood, the `Module` base class is keeping track of the network's weights which are contained within each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        \n",
    "        # this line extends the nn.Module base class. \n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5) # 5x5\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        # linear layers are often used in the final stages of a network\n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10) \n",
    "\n",
    "    def forward(self,t):\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break the code down:\n",
    "\n",
    "## Convolutional layers\n",
    "\n",
    "The choice of number of layers here is arbitrary; this type of configuration is best approached through experimentation\n",
    "\n",
    "```python\n",
    "self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "```\n",
    "### Hyperparameters\n",
    "\n",
    "- `kernel_size` - sets the filter size. 'kernel' and 'filter' are interchangeable terms\n",
    "- `out_channels` - sets the number of filters. One filter produces one output channel. output channels are also called `feature maps`.\n",
    "- `in_channels` - number of input channels\n",
    "\n",
    "In our case above, we are saying that we want **1 input channel** that will be convolved by `six different filters` which will create six output channels\n",
    "\n",
    "The **in_channel** hyperperameter in the `first conv layer` is dependent on the number of color channels of our input data. We have it as **1** because we have grayscale images.\n",
    "\n",
    "The second conv layer's input matches the output size of the previous conv layer\n",
    "\n",
    "## Linear layers\n",
    "\n",
    "When switching from conv2d layers to Linear, the tensors must be flattened. \n",
    "\n",
    "`NOTE`: fc = fully connected layers (Linear, Dense, Fully connected all refer to the same thing)\n",
    "\n",
    "```python\n",
    "self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "self.out = nn.Linear(in_features=60, out_features=10) \n",
    "```\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "- `in_features` - the layer input size\n",
    "- `out_features` - size fo the layer output\n",
    "\n",
    "The **out_features** in the `self.out` layer correspond to the number of our classes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "network = Network()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at the above output:\n",
    "- `stride` - tells the conv layer how far the filter should slide after each operation in the overall convolution\n",
    "- `bias` - an additive parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\t\ttorch.Size([6, 1, 5, 5])\n",
      "conv1.bias\t\ttorch.Size([6])\n",
      "conv2.weight\t\ttorch.Size([12, 6, 5, 5])\n",
      "conv2.bias\t\ttorch.Size([12])\n",
      "fc1.weight\t\ttorch.Size([120, 192])\n",
      "fc1.bias\t\ttorch.Size([120])\n",
      "fc2.weight\t\ttorch.Size([60, 120])\n",
      "fc2.bias\t\ttorch.Size([60])\n",
      "out.weight\t\ttorch.Size([10, 60])\n",
      "out.bias\t\ttorch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,param in network.named_parameters():\n",
    "    print(f\"{name}\\t\\t{param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74257a0a5c0181bc4827c74976dbddecd68f5367eb1980f961c7a318e63ecaee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
